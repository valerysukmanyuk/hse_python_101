{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valerysukmanyuk/hse_python_101/blob/h%2Fw/w/workbook/3_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning** (чистка данных) - этап предварительной обработки данных для анализа данных и машинного обучения.\n",
        "\n",
        "**Примеры Data Cleaning:**\n",
        "- удаление избыточных столбцов из табличных данных;\n",
        "- приведение текста к нижнему регистру;\n",
        "- чистка текста от HTML-артефактов\n",
        "\n",
        "Загрузим тренировочный датасет, почистим его и проанализируем результаты."
      ],
      "metadata": {
        "id": "Vl6M3rDU5XhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1: Загрузка данных\n",
        "\n",
        "Загрузим тренировочный датасет и посмотрим на наши данные.\n",
        "\n",
        "Представим, что мы загрузили статью в формате HTML.\n",
        "\n",
        "Скачаем ее и выведем на экран первые 100 символов с помощью слайсинга (среза)."
      ],
      "metadata": {
        "id": "LK_zsNv26Tsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем тренировочные данные\n",
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbak8zIx8i6_",
        "outputId": "6cb26675-4814-4a5b-c30b-b4697ca7d8a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-05 10:52:17--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/data_cleaning.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2377 (2.3K) [text/plain]\n",
            "Saving to: ‘data_cleaning.txt’\n",
            "\n",
            "\rdata_cleaning.txt     0%[                    ]       0  --.-KB/s               \rdata_cleaning.txt   100%[===================>]   2.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-05 10:52:17 (26.2 MB/s) - ‘data_cleaning.txt’ saved [2377/2377]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# запишем данные в переменную data\n",
        "with open('data_cleaning.txt', 'r') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "OJ68oc8E8r9P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# выведите на экран первые 100 символов с помощью слайсинга\n",
        "\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ9GtP8s86V8",
        "outputId": "228c83a3-ad4e-479a-a6a1-34b0fa700193"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Sample HTML Document</title>\n",
            "</head>\n",
            "<body>\n",
            "    <h1>Welcome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2: Удаление артефактов\n",
        "\n",
        "В данных много артефактов - HTML-тегов.\n",
        "\n",
        "Удалим HTML-артефакты с помощью регулярных выражений RegEx"
      ],
      "metadata": {
        "id": "XIGQ9xGQ6t1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# пропишем паттерн для поиска HTML-тегов вида <tag> ... </tag>\n",
        "import re   # загрузим библиотеку для обработки регулярных выражений\n",
        "\n",
        "tag_pattern = r'<[^>]+>'    # паттерн для поиска тегов"
      ],
      "metadata": {
        "id": "aQ0ka1oq9uVz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используйте функцию `re.sub` (substitution) для чистки данных\n",
        "\n",
        "`re.sub` ищет в строке `string` соответствия RegEx-паттерну `pattern` и меняет найденное на указанную строку `repl`\n",
        "\n",
        "Как используем функцию: `re.sub(pattern, repl, string)`\n",
        "\n",
        "- `pattern` - паттерн RegEx, соответствия которому будет искать функция\n",
        "- `repl` - на что будем менять найденные соответствия\n",
        "- `string` - где будем искать, наш датасет\n",
        "\n",
        "Запишите результат в переменную `clean_text` и выведите на экран с 720-го по 800-ый символ очищенного текста\n",
        "\n",
        "Используйте слайсинг"
      ],
      "metadata": {
        "id": "h8oleHAo_UaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсказки:\n",
        "# используйте паттерн, записанный в переменную tag_pattern\n",
        "# замените результат на пустую строку \"\"\n",
        "clean_text = re.sub(tag_pattern, '', data)\n",
        "print(clean_text[720:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjqjGi8P-H6O",
        "outputId": "26bb389a-ee53-44fc-dee1-dcc5e240368e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's crucial to handle HTML entities such as &lt;div&gt;, &lt;p&gt;, &amp;, etc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы удалили не все специальные символы HTML\n",
        "\n",
        "Создадим еще один паттерн и повторим процедуру"
      ],
      "metadata": {
        "id": "fZAWGBC7Ajr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_pattern = r'&\\w+;'    # паттерн для поиска специальных символов"
      ],
      "metadata": {
        "id": "jIftruIgBuQj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используйте `re.sub` для удаления этих символов\n",
        "\n",
        "Теперь функция принимает на вход паттерн `symbols_pattern` и текст `clean_text`\n",
        "\n",
        "Перезапишите переменную `clean_text`\n",
        "\n",
        "Выведите на экран с 720-го по 800-ый символ, чтобы убедиться в том, что чистка прошла успешно"
      ],
      "metadata": {
        "id": "LJ19ehiFB5d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = re.sub(symbols_pattern, \"\", clean_text)\n",
        "print(clean_text[720:800])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsX39hWDCLR6",
        "outputId": "809cb48b-278e-4c31-aef9-56ca5d6440c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It's crucial to handle HTML entities such as div, p, , etc. HTML entities are s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В нашем тексте остались двойные пробелы\n",
        "\n",
        "Уберем им с помощью очередного паттерна"
      ],
      "metadata": {
        "id": "mP70Rf3oCKNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# выведите на экран первые 100 символов вашего текущего результата\n",
        "# на этот раз не используйте print\n",
        "clean_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GMGJDpaEDHx5",
        "outputId": "a0dc9cc7-efe9-481a-da41-a796a0a35ea5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n    Sample HTML Document\\n\\n\\n    Welcome to Data Cleaning\\n    This is a sample paragraph with HTML '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем паттерн для поиска двойных пробелов\n",
        "\n",
        "Повторите процедуру, перезапишите результат в `clean_text` и выведите первые 100 символов\n",
        "\n",
        "Что мы запишем в переменную `repl`, чтобы не удалить абсолютно все пробелы?"
      ],
      "metadata": {
        "id": "GpgXBzMxDicX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space_pattern = r'\\s+'\n",
        "\n",
        "clean_text = re.sub(space_pattern, ' ', clean_text)\n",
        "clean_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aQ-ZqbEcDcIE",
        "outputId": "b78a265a-5aa7-457e-c3a2-367f5c8b9082"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sample HTML Document Welcome to Data Cleaning This is a sample paragraph with HTML artifacts such a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3: Смена регистра\n",
        "\n",
        "Приведем все слова к нижнему регистру с помощью функции `lower`\n",
        "\n",
        "Запишем результат в переменную `text_lower` и выведем на экран последние 100 символов"
      ],
      "metadata": {
        "id": "Hwtj4l2x6bwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_lower = clean_text.lower()\n",
        "text_lower[-100:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NbmH8JL0EPeg",
        "outputId": "fc190043-5522-4d61-c849-220eb055ca11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e learning models, making predictions, or generating insights to support decision-making processes. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4: Удаление стоп-слов\n",
        "\n",
        "Удалим частотные слова, которые создают шум для решения задач\n",
        "\n",
        "Загрузим список стоп-слов"
      ],
      "metadata": {
        "id": "vkxdtN1Q6mwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ypsKpKBE6T-",
        "outputId": "a9c8ebe9-920b-4dab-ddc5-3dbef3341b69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-05 10:52:43--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/data/stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 954 [text/plain]\n",
            "Saving to: ‘stopwords.txt’\n",
            "\n",
            "\rstopwords.txt         0%[                    ]       0  --.-KB/s               \rstopwords.txt       100%[===================>]     954  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-05 10:52:43 (59.3 MB/s) - ‘stopwords.txt’ saved [954/954]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# запишем данные в переменную stopwords\n",
        "with open('stopwords.txt', 'r') as f:\n",
        "  stopwords = f.read().split()"
      ],
      "metadata": {
        "id": "_c1xfdkgFNcg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите на экран первые 10 стоп-слов"
      ],
      "metadata": {
        "id": "nansznnrFVN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pctau5NgFYJG",
        "outputId": "c24a4064-eae7-4caa-df57-e662c9fec2f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью `random` мы можем \"вытянуть\" из списка стоп-слов случайное слово"
      ],
      "metadata": {
        "id": "7C4R5y63Fqrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.choice(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8SX-lcCAFjNc",
        "outputId": "7fc62855-edcd-49dc-e990-43f3305dd746"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'above'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Вытяните\" еще одно случайное слово и запишите его в переменную `random_word`"
      ],
      "metadata": {
        "id": "tPDPQYYTFwsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_word = random.choice(stopwords)"
      ],
      "metadata": {
        "id": "oJkDb27LF75t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверьте, есть ли это слово в `text_lower` с помощью `in`\n",
        "\n",
        "Выведите на экран это слово"
      ],
      "metadata": {
        "id": "erv_tjszGZlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if random_word in text_lower:\n",
        "  print(f'Результат проверки: True')\n",
        "else:\n",
        "  print(f'Результат проверки: False')\n",
        "print(f'Случайное слово {random_word}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2NJtaSOGBDT",
        "outputId": "29d34ddb-5df4-4e3f-8bb6-7d293a515675"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат проверки: False\n",
            "Случайное слово these\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте сгенерировать еще несколько слов и проверить их наличие в `text_lower`\n",
        "\n",
        "Для этого запустите повторно две последние ячейки"
      ],
      "metadata": {
        "id": "VBJJHLvrHCCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Вот так будет выглядеть текст после удаления стоп-слов _без_ токенизации\n",
        "Заменятся все аналогичные сочетания знаков\n",
        "Поэтому перед _удалением_ стоп-слов, проведем токенизацию\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "gY7oeXTXGW0D",
        "outputId": "29a5fe30-9fd3-447b-9de7-5ed01589fdd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' s mple html  cu nt  lco    d t  cle n ng t   s   s mple p r gr ph w th html  rt f cts    s bold  nd  t l c text. d t  cle n ng  s  n essent  l process  n prep r ng d t     n lys s.  t  nvolves v r ous techn ques   cle n, tr ns m,  nd preprocess d t .  n d t  cle n ng,  t\\'s  mp t nt   remove s p w ds l ke \"t \", \" nd\", \" \", etc. s p w ds  re comm  w ds th t  re  ten f ltered     text d t   c use t y    t c rry s gn f c nt   n ng.  re\\'s   t r p r gr ph.   t  s text  s  n  perc se   lo rc se.  t\\'s  mp t nt   st nd rd ze t  text c se   ensure c s stency  n t  d t set. t  c n    ch eved   c vert ng  ll text   lo rc se    perc se.  t\\'s cruc  l   h ndle html ent t es    s d v, p, , etc. html ent t es  re spec  l ch r cters   symbols th t h ve spec f c   n ngs  n html. t y need     properly h ndled    vo d  ssues   d t  process ng. d t  cle n ng  l   nvolves de l ng w th m ss ng v lues. m ss ng v lues c n occur due   v r ous re s s    s  ncomplete d t  collect     d t  entry err s.  t\\'s essent  l    dent fy  nd h ndle m ss ng v lues  ppropr  tely    vo d b  s  n t   n lys s. text d t   ten c t  ns   se    s punctu t   m rks, spec  l ch r cters,  nd d g ts. remov ng   se   text d t   s necess ry   focus   t    n ngful c tent. techn ques    s regul r express  s c n   used     se remov l.   t r  mp t nt  spect   d t  cle n ng  s ded l c t  . d l c te rec ds  n   d t set c n skew  n lys s results  nd le d    n ccur te c clus  s.  dent fy ng  nd remov ng d l c te rec ds ensures d t   ntegr ty  nd  mproves t  qu l ty    n lys s.  fter cle n ng t  d t ,  t\\'s essent  l   per m expl  t y d t   n lys s (ed )   g  n  ns ghts  nd  dent fy p tterns. ed   nvolves v su l z ng d t , comput ng summ ry st t st cs,  nd expl  ng rel t  sh ps  t en v r  bles.  ce t  d t   s cle ned  nd  n lyzed,  t c n   used   v r ous purposes    s bu ld ng m ch ne le rn ng models, m k ng pred ct  s,   gener t ng  ns ghts   s p t dec s  -m k ng processes. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 5: Токенизация\n",
        "\n",
        "Токенизируем датасет для дальнейшей работы\n",
        "\n",
        "Создадим 2 набора токенов: с сегментацией по предложениям и с сегментацией по словам"
      ],
      "metadata": {
        "id": "Mepvb0Kw7Ncq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте переменную `sentences`\n",
        "\n",
        "С помощью `split` разделите текст на предложения (сегменты, разделенные знаком `.`)\n",
        "\n",
        "Выведите на экран первые 10 элементов `sentences`"
      ],
      "metadata": {
        "id": "Me63a7SNLa6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_lower.split(\".\")\n",
        "print(sentences[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G13fM_27M1t",
        "outputId": "754ba0e8-338a-45f7-9819-fd7d63312f09"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' sample html document welcome to data cleaning this is a sample paragraph with html artifacts such as bold and italic text', ' data cleaning is an essential process in preparing data for analysis', ' it involves various techniques to clean, transform, and preprocess data', ' in data cleaning, it\\'s important to remove stop words like \"the\", \"and\", \"of\", etc', ' stop words are common words that are often filtered out from text data because they do not carry significant meaning', \" here's another paragraph\", ' sometimes text is in uppercase or lowercase', \" it's important to standardize the text case to ensure consistency in the dataset\", ' this can be achieved by converting all text to lowercase or uppercase', \" it's crucial to handle html entities such as div, p, , etc\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте переменную `tokens`\n",
        "\n",
        "С помощью `split` разделите текст `text_lower` на слова\n",
        "\n",
        "Выведите первые 10 элементов"
      ],
      "metadata": {
        "id": "6J_C8cq0L2rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text_lower.split()\n",
        "print(tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj3dXh576a5A",
        "outputId": "ba7f201a-956a-4556-8fa1-1ec69596394a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'html', 'document', 'welcome', 'to', 'data', 'cleaning', 'this', 'is', 'a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Удалим стоп-слова"
      ],
      "metadata": {
        "id": "5Q7FfNK9MJ_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_tokens = []\n",
        "\n",
        "for token in tokens:  # итерация по списку токенов tokens\n",
        "  if token not in stopwords:  # проверяем отсутствие токена в списке стоп-слов\n",
        "    clean_tokens.append(token)  # добавляем токен в новый очищенный список токенов, если его нет в стоп-словах\n",
        "print(clean_tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMy-_DNJ0HF3",
        "outputId": "0b5e7798-5292-45cf-969a-90a6f4610d33"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'html', 'document', 'welcome', 'data', 'cleaning', 'sample', 'paragraph', 'html', 'artifacts']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# И еще одно задание...\n",
        "\n",
        "В ячейке ниже вы сможете загрузить еще один текст\n",
        "\n",
        "Используйте свой код и код из задания, чтобы\n",
        "\n",
        "1. удалить артефакты (html-теги, специальные символы и двойные пробелы)\n",
        "\n",
        "2. привести текст к нижнему регистру\n",
        "\n",
        "3. токенизировать текст по предложениям\n",
        "\n",
        "4. токенизировать текст по словам\n",
        "\n",
        "5. удалить стоп-слова"
      ],
      "metadata": {
        "id": "0EYfMpHZNUkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE6b-OKsNqK_",
        "outputId": "87803387-9a11-4e87-ebce-3ce134474ce9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-05 11:10:45--  https://raw.githubusercontent.com/vifirsanova/hse-python-course/main/extracurricular/artefacts.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 845 [text/plain]\n",
            "Saving to: ‘artefacts.txt’\n",
            "\n",
            "\rartefacts.txt         0%[                    ]       0  --.-KB/s               \rartefacts.txt       100%[===================>]     845  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-05 11:10:45 (22.0 MB/s) - ‘artefacts.txt’ saved [845/845]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# запишем данные в переменную artefacts\n",
        "with open('artefacts.txt', 'r') as f:\n",
        "  artefacts = f.read()"
      ],
      "metadata": {
        "id": "CT7eVLpHOMTQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artefacts = re.sub(tag_pattern, \" \", artefacts)\n",
        "artefacts = re.sub(symbols_pattern, \" \", artefacts)\n",
        "artefacts = re.sub(space_pattern, ' ', artefacts)\n",
        "artefacts = artefacts.lower()\n",
        "tokens_sen = artefacts.split(\".\")\n",
        "tokens_word = artefacts.split()\n",
        "\n",
        "clean_artefacts_tokens = []\n",
        "\n",
        "for token in tokens_word:\n",
        "  if token not in stopwords:\n",
        "    clean_artefacts_tokens.append(token)\n",
        "\n",
        "\n",
        "print(clean_artefacts_tokens)"
      ],
      "metadata": {
        "id": "9g-geUOsORlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c88555-8d5e-45a4-a68f-d12331c084f8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample', 'web', 'page', 'welcome', 'website', 'sample', 'text', 'website.', 'can', 'contact', 'us', 'info@example.com', '.', 'latest', 'news', 'breaking', 'news:', 'important', 'announcement', 'lorem', 'ipsum', 'dolor', 'sit', 'amet,', 'consectetur', 'adipiscing', 'elit.', 'vivamus', 'lacinia,', 'arcu', 'fermentum', 'tincidunt.', '2023', 'website.', 'rights', 'reserved.', '|', 'privacy', 'policy', '|', 'contact', 'us', \"console.log('this\", 'javascript', 'content', 'runs', \"browser.');\"]\n"
          ]
        }
      ]
    }
  ]
}